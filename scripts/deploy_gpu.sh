#!/usr/bin/env bash
set -euo pipefail

# â”€â”€â”€ 1) Ensure required env vars are set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
: "${RUNPOD_API_KEY:?RUNPOD_API_KEY must be set in env}"
: "${RUNPOD_POD_ID:?RUNPOD_POD_ID must be set in env}"
: "${GHCR_TOKEN:?GHCR_TOKEN must be set in env}"
: "${GHCR_USER:?GHCR_USER must be set in env}"
: "${API_AUTH_TOKEN:?API_AUTH_TOKEN must be set in env}"
: "${GPU_API_URL:?GPU_API_URL must be set in env}"
: "${FAISS_INDEX_PATH:?FAISS_INDEX_PATH must be set in env}"

# â”€â”€â”€ 2) Compute GHCR image name â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GHCR_NS="${GHCR_USER,,}"
IMAGE="ghcr.io/${GHCR_NS}/faiss-gpu-api:latest"

# â”€â”€â”€ 3) Clean up any old local images â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ğŸ—‘ Cleaning old Docker imagesâ€¦"
docker rmi -f faiss-gpu-api:latest "${IMAGE}" 2>/dev/null || true
docker system prune -af

# â”€â”€â”€ 4) Pre-pull CUDA base â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ğŸ”„ Pre-pulling CUDA base imageâ€¦"
docker pull nvidia/cuda:11.8.0-runtime-ubuntu22.04

# â”€â”€â”€ 5) Build GPU API Docker image â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ğŸ”¨ Building GPU Docker imageâ€¦"
docker build \
  --network host \
  --no-cache \
  -f docker/Dockerfile.gpu \
  -t faiss-gpu-api:latest \
  .

# â”€â”€â”€ 6) Push to GHCR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ğŸ”‘ Logging into ghcr.ioâ€¦"
echo "${GHCR_TOKEN}" | docker login ghcr.io -u "${GHCR_USER}" --password-stdin

echo "ğŸš€ Tagging and pushing ${IMAGE}â€¦"
docker tag faiss-gpu-api:latest "${IMAGE}"
docker push "${IMAGE}"

# â”€â”€â”€ 7) Deploy to RunPod via REST API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REST="https://rest.runpod.io/v1"

# 7a) Make sure pod is running
STATUS=$(curl -s -H "Authorization: Bearer ${RUNPOD_API_KEY}" \
  "${REST}/pods/${RUNPOD_POD_ID}" | jq -r .desiredStatus // echo UNKNOWN)

if [[ "$STATUS" != "RUNNING" ]]; then
  echo "âš¡ Pod is $STATUS â€” starting spot instanceâ€¦"
  curl -s -X POST \
    -H "Authorization: Bearer ${RUNPOD_API_KEY}" \
    "${REST}/pods/${RUNPOD_POD_ID}/start" \
    -d '{}'
  echo "â± Waiting 30s for pod initâ€¦"
  sleep 30
fi

# 7b) Tell RunPod to run our new image
echo "ğŸ“¦ Deploying GPU container on RunPodâ€¦"
curl -s -X POST \
  -H "Authorization: Bearer ${RUNPOD_API_KEY}" \
  -H "Content-Type: application/json" \
  "${REST}/pods/${RUNPOD_POD_ID}/run" \
  -d "$(jq -n \
      --arg image "$IMAGE" \
      --arg token "$API_AUTH_TOKEN" \
      --arg path  "$FAISS_INDEX_PATH" \
     '{
        image: $image,
        env: {
          API_AUTH_TOKEN: $token,
          FAISS_INDEX_PATH: $path
        },
        ports: ["8000/http"]
      }')"

echo "âœ… GPU API deployedâ€”try:"
echo "   curl -X POST \\"
echo "     -H \"Authorization: Bearer ${API_AUTH_TOKEN}\" \\"
echo "     -F \"file=@test.jpg\" \\"
echo "     ${GPU_API_URL}/search?top_k=3"
